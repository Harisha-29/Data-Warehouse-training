{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JCcEYg4zJdwg"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PracticeProject\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales\")\n",
        "\n",
        "# Customers Data\n",
        "customers_data = [\n",
        "    (101, 'Ali', 'ali@gmail.com', 'Mumbai', '2022-05-10'),\n",
        "    (102, 'Neha', 'neha@yahoo.com', 'Delhi', '2023-01-15'),\n",
        "    (103, 'Ravi', 'ravi@hotmail.com', 'Bangalore', '2021-11-01'),\n",
        "    (104, 'Sneha', 'sneha@outlook.com', 'Hyderabad', '2020-07-22'),\n",
        "    (105, 'Amit', 'amit@gmail.com', 'Chennai', '2023-03-10'),\n",
        "]\n",
        "\n",
        "orders_data = [\n",
        "    (1, 101, 'Laptop', 'Electronics', 2, 50000.0, '2024-01-10'),\n",
        "    (2, 101, 'Mouse', 'Electronics', 1, 1200.0, '2024-01-15'),\n",
        "    (3, 102, 'Tablet', 'Electronics', 1, 20000.0, '2024-02-01'),\n",
        "    (4, 103, 'Bookshelf', 'Furniture', 1, 3500.0, '2024-02-10'),\n",
        "    (5, 104, 'Mixer', 'Appliances', 1, 5000.0, '2024-02-15'),\n",
        "    (6, 105, 'Notebook', 'Stationery', 5, 500.0, '2024-03-01'),\n",
        "    (7, 102, 'Phone', 'Electronics', 1, 30000.0, '2024-03-02'),\n",
        "]\n",
        "\n",
        "# Create DataFrames\n",
        "customers_df = spark.createDataFrame(customers_data, [\"CustomerID\", \"Name\", \"Email\", \"City\", \"SignupDate\"])\n",
        "orders_df = spark.createDataFrame(orders_data, [\"OrderID\", \"CustomerID\", \"Product\", \"Category\", \"Quantity\", \"Price\", \"OrderDate\"])\n",
        "\n",
        "# Save DataFrames as Hive tables\n",
        "customers_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr, when, lower, year, lit, coalesce\n",
        "\n",
        "# 1. Add TotalAmount = Price * Quantity\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "orders_df.show()\n",
        "\n",
        "# 2. Filter orders with TotalAmount > 10000\n",
        "orders_df.filter(col(\"TotalAmount\") > 10000).show()\n",
        "\n",
        "# 3. Standardize the City field in customers_df\n",
        "customers_df = customers_df.withColumn(\"City\", lower(col(\"City\")))\n",
        "customers_df.show()\n",
        "\n",
        "# 4. Extract year from OrderDate\n",
        "orders_df = orders_df.withColumn(\"OrderYear\", year(col(\"OrderDate\")))\n",
        "orders_df.select(\"OrderID\", \"OrderDate\", \"OrderYear\").show()\n",
        "\n",
        "# 5. Fill nulls in Price with default value 0\n",
        "orders_df = orders_df.fillna({\"Price\": 0.0})\n",
        "customers_df = customers_df.fillna({\"Email\": \"not_provided@example.com\"})\n",
        "\n",
        "# 6. Categorize orders based on TotalAmount\n",
        "orders_df = orders_df.withColumn(\"OrderCategory\",\n",
        "    when(col(\"TotalAmount\") < 5000, \"Low\")\n",
        "    .when((col(\"TotalAmount\") >= 5000) & (col(\"TotalAmount\") <= 20000), \"Medium\")\n",
        "    .otherwise(\"High\"))\n",
        "orders_df.select(\"OrderID\", \"TotalAmount\", \"OrderCategory\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoxQ6FhVLvpE",
        "outputId": "a205af05-0a7b-40cb-d0cd-c6bfa41218fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+-------+----------+---------+\n",
            "|OrderID| OrderDate|OrderYear|\n",
            "+-------+----------+---------+\n",
            "|      1|2024-01-10|     2024|\n",
            "|      2|2024-01-15|     2024|\n",
            "|      3|2024-02-01|     2024|\n",
            "|      4|2024-02-10|     2024|\n",
            "|      5|2024-02-15|     2024|\n",
            "|      6|2024-03-01|     2024|\n",
            "|      7|2024-03-02|     2024|\n",
            "+-------+----------+---------+\n",
            "\n",
            "+-------+-----------+-------------+\n",
            "|OrderID|TotalAmount|OrderCategory|\n",
            "+-------+-----------+-------------+\n",
            "|      1|   100000.0|         High|\n",
            "|      2|     1200.0|          Low|\n",
            "|      3|    20000.0|       Medium|\n",
            "|      4|     3500.0|          Low|\n",
            "|      5|     5000.0|       Medium|\n",
            "|      6|     2500.0|          Low|\n",
            "|      7|    30000.0|         High|\n",
            "+-------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Register tables (if not using Hive context)\n",
        "orders_df.createOrReplaceTempView(\"orders\")\n",
        "customers_df.createOrReplaceTempView(\"customers\")\n",
        "\n",
        "# 7. Orders made by Ali\n",
        "spark.sql(\"\"\"\n",
        "SELECT o.*\n",
        "FROM orders o\n",
        "JOIN customers c ON o.CustomerID = c.CustomerID\n",
        "WHERE c.Name = 'Ali'\n",
        "\"\"\").show()\n",
        "\n",
        "# 8. Total spending by each customer\n",
        "spark.sql(\"\"\"\n",
        "SELECT c.Name, SUM(o.TotalAmount) as TotalSpent\n",
        "FROM orders o\n",
        "JOIN customers c ON o.CustomerID = c.CustomerID\n",
        "GROUP BY c.Name\n",
        "\"\"\").show()\n",
        "\n",
        "# 9. Category with highest total revenue\n",
        "spark.sql(\"\"\"\n",
        "SELECT Category, SUM(TotalAmount) as Revenue\n",
        "FROM orders\n",
        "GROUP BY Category\n",
        "ORDER BY Revenue DESC\n",
        "LIMIT 1\n",
        "\"\"\").show()\n",
        "\n",
        "# 10. Create a view for customer_orders\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE TEMP VIEW customer_orders AS\n",
        "SELECT c.Name AS CustomerName, o.Product, o.TotalAmount\n",
        "FROM orders o\n",
        "JOIN customers c ON o.CustomerID = c.CustomerID\n",
        "\"\"\")\n",
        "\n",
        "# 11. Query products ordered after Feb 2024\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT co.CustomerName, co.Product, co.TotalAmount\n",
        "FROM customer_orders co\n",
        "JOIN orders o ON co.Product = o.Product\n",
        "WHERE o.OrderDate > '2024-02-01'\n",
        "\"\"\").show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo9-kUarL_ui",
        "outputId": "fc691e34-3572-4188-ba1c-340b49a48d51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderCategory|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|         High|\n",
            "|      2|       101|  Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|          Low|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "\n",
            "+-----+----------+\n",
            "| Name|TotalSpent|\n",
            "+-----+----------+\n",
            "| Ravi|    3500.0|\n",
            "|Sneha|    5000.0|\n",
            "| Amit|    2500.0|\n",
            "| Neha|   50000.0|\n",
            "|  Ali|  101200.0|\n",
            "+-----+----------+\n",
            "\n",
            "+-----------+--------+\n",
            "|   Category| Revenue|\n",
            "+-----------+--------+\n",
            "|Electronics|151200.0|\n",
            "+-----------+--------+\n",
            "\n",
            "+------------+---------+-----------+\n",
            "|CustomerName|  Product|TotalAmount|\n",
            "+------------+---------+-----------+\n",
            "|        Neha|    Phone|    30000.0|\n",
            "|        Ravi|Bookshelf|     3500.0|\n",
            "|        Amit| Notebook|     2500.0|\n",
            "|       Sneha|    Mixer|     5000.0|\n",
            "+------------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Global Temp View\n",
        "customers_df.createOrReplaceGlobalTempView(\"customers\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM global_temp.customers WHERE City = 'mumbai'\").show()\n",
        "\n",
        "# 13. Save orders_df with TotalAmount to Parquet\n",
        "orders_df.write.mode(\"overwrite\").parquet(\"/tmp/orders_parquet\")\n",
        "\n",
        "# 14. Read back and count orders\n",
        "orders_parquet = spark.read.parquet(\"/tmp/orders_parquet\")\n",
        "orders_parquet.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THZKNR2hMysf",
        "outputId": "88a0ada8-268f-406b-b2ba-a86e72b26d63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-------------+------+----------+\n",
            "|CustomerID|Name|        Email|  City|SignupDate|\n",
            "+----------+----+-------------+------+----------+\n",
            "|       101| Ali|ali@gmail.com|mumbai|2022-05-10|\n",
            "+----------+----+-------------+------+----------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf, concat_ws, regexp_replace, to_date, datediff, current_date\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# 15. Email masking UDF\n",
        "def mask_email(email):\n",
        "    if email:\n",
        "        parts = email.split(\"@\")\n",
        "        return parts[0][0] + \"***@\" + parts[1]\n",
        "    return email\n",
        "\n",
        "mask_email_udf = udf(mask_email, StringType())\n",
        "customers_df = customers_df.withColumn(\"MaskedEmail\", mask_email_udf(col(\"Email\")))\n",
        "customers_df.select(\"Email\", \"MaskedEmail\").show()\n",
        "\n",
        "# 16. Use concat_ws to create full label\n",
        "customers_df = customers_df.withColumn(\"Label\", concat_ws(\" \", col(\"Name\"), lit(\"from\"), col(\"City\")))\n",
        "customers_df.select(\"Label\").show()\n",
        "\n",
        "# 17. Clean product names\n",
        "orders_df = orders_df.withColumn(\"CleanProduct\", regexp_replace(col(\"Product\"), \"[^a-zA-Z0-9 ]\", \"\"))\n",
        "orders_df.select(\"Product\", \"CleanProduct\").show()\n",
        "\n",
        "# 18. Calculate customer age in days\n",
        "customers_df = customers_df.withColumn(\"SignupDate\", to_date(col(\"SignupDate\")))\n",
        "customers_df = customers_df.withColumn(\"CustomerAgeDays\", datediff(current_date(), col(\"SignupDate\")))\n",
        "customers_df.select(\"Name\", \"CustomerAgeDays\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3yFzlx-M-sX",
        "outputId": "a7b19bc9-1d5a-4bea-e922-3f0e4a3dfbcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+\n",
            "|            Email|     MaskedEmail|\n",
            "+-----------------+----------------+\n",
            "|    ali@gmail.com|  a***@gmail.com|\n",
            "|   neha@yahoo.com|  n***@yahoo.com|\n",
            "| ravi@hotmail.com|r***@hotmail.com|\n",
            "|sneha@outlook.com|s***@outlook.com|\n",
            "|   amit@gmail.com|  a***@gmail.com|\n",
            "+-----------------+----------------+\n",
            "\n",
            "+--------------------+\n",
            "|               Label|\n",
            "+--------------------+\n",
            "|     Ali from mumbai|\n",
            "|     Neha from delhi|\n",
            "| Ravi from bangalore|\n",
            "|Sneha from hyderabad|\n",
            "|   Amit from chennai|\n",
            "+--------------------+\n",
            "\n",
            "+---------+------------+\n",
            "|  Product|CleanProduct|\n",
            "+---------+------------+\n",
            "|   Laptop|      Laptop|\n",
            "|    Mouse|       Mouse|\n",
            "|   Tablet|      Tablet|\n",
            "|Bookshelf|   Bookshelf|\n",
            "|    Mixer|       Mixer|\n",
            "| Notebook|    Notebook|\n",
            "|    Phone|       Phone|\n",
            "+---------+------------+\n",
            "\n",
            "+-----+---------------+\n",
            "| Name|CustomerAgeDays|\n",
            "+-----+---------------+\n",
            "|  Ali|           1121|\n",
            "| Neha|            871|\n",
            "| Ravi|           1311|\n",
            "|Sneha|           1778|\n",
            "| Amit|            817|\n",
            "+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}