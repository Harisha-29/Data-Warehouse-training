{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JAOE78nbFy0J"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"HR_Analytics\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the correct folder path\n",
        "base_path = \"/content/drive/MyDrive/HR_Analytics_Data/\"  # Change this to your actual folder name\n",
        "\n",
        "# Step 1: Initialize Spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"HR_Analytics\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Read CSV and JSON\n",
        "employees_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(base_path + \"employees.csv\")\n",
        "attendance_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(base_path + \"attendance.csv\")\n",
        "bonuses_df = spark.read.option(\"multiline\", True).json(base_path + \"bonuses.json\")\n",
        "\n",
        "# Step 3: Show schema and sample\n",
        "employees_df.printSchema()\n",
        "attendance_df.printSchema()\n",
        "bonuses_df.printSchema()\n",
        "\n",
        "employees_df.show(3)\n",
        "attendance_df.show(3)\n",
        "bonuses_df.show(3)\n",
        "\n",
        "#Step 4: Count distinct departments\n",
        "from pyspark.sql.functions import countDistinct\n",
        "employees_df.select(countDistinct(\"Department\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg-oDcCPHib5",
        "outputId": "64208bca-4172-41e0-a8da-7b54705dcf05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- JoinDate: date (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- ManagerID: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Bonus: long (nullable = true)\n",
            " |-- EmpID: long (nullable = true)\n",
            " |-- Year: long (nullable = true)\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-----+----------+-------+\n",
            "|EmpID|      Date| Status|\n",
            "+-----+----------+-------+\n",
            "|    1|2024-04-01|Present|\n",
            "|    1|2024-04-02|Present|\n",
            "|    2|2024-04-01| Absent|\n",
            "+-----+----------+-------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-----+-----+----+\n",
            "|Bonus|EmpID|Year|\n",
            "+-----+-----+----+\n",
            "| 5000|    1|2023|\n",
            "| 7000|    2|2023|\n",
            "| 6500|    3|2023|\n",
            "+-----+-----+----+\n",
            "only showing top 3 rows\n",
            "\n",
            "+--------------------------+\n",
            "|count(DISTINCT Department)|\n",
            "+--------------------------+\n",
            "|                         3|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date, datediff, current_date, round, col\n",
        "\n",
        "# Fix JoinDate if needed\n",
        "employees_df = employees_df.withColumn(\"JoinDate\", to_date(col(\"JoinDate\"), \"yyyy-MM-dd\"))\n",
        "\n",
        "# Tenure in years\n",
        "employees_df = employees_df.withColumn(\"TenureYears\", round(datediff(current_date(), col(\"JoinDate\")) / 365, 1))\n",
        "\n",
        "# Join bonus to compute TotalCompensation\n",
        "emp_bonus_df = employees_df.join(bonuses_df, \"EmpID\", \"left\") \\\n",
        "                           .withColumn(\"TotalCompensation\", col(\"Salary\") + col(\"Bonus\"))\n",
        "\n",
        "# Show all\n",
        "emp_bonus_df.select(\"EmpID\", \"Name\", \"JoinDate\", \"TenureYears\", \"ManagerID\", \"Salary\", \"Bonus\", \"TotalCompensation\").show()\n",
        "\n",
        "# Filter >2 years\n",
        "emp_bonus_df.filter(col(\"TenureYears\") > 2).show()\n",
        "\n",
        "# Employees with manager\n",
        "emp_bonus_df.filter(col(\"ManagerID\").isNotNull()).show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JITav903MYxH",
        "outputId": "ab26ede6-89e6-486b-a1b5-95b3c9369a6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+-----------+---------+------+-----+-----------------+\n",
            "|EmpID|  Name|  JoinDate|TenureYears|ManagerID|Salary|Bonus|TotalCompensation|\n",
            "+-----+------+----------+-----------+---------+------+-----+-----------------+\n",
            "|    1| Anita|2021-05-01|        4.1|     NULL| 55000| 5000|            60000|\n",
            "|    2|   Raj|2020-03-15|        5.2|        1| 80000| 7000|            87000|\n",
            "|    3|Simran|2022-07-10|        2.9|        1| 75000| 6500|            81500|\n",
            "|    4| Aamir|2019-11-20|        5.6|        1| 60000| 6000|            66000|\n",
            "|    5| Nisha|2023-01-05|        2.4|        1| 50000| 4000|            54000|\n",
            "+-----+------+----------+-----------+---------+------+-----+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|            60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avg salary per department\n",
        "employees_df.groupBy(\"Department\").avg(\"Salary\").show()\n",
        "\n",
        "# Count of employees per manager\n",
        "employees_df.groupBy(\"ManagerID\").count().show()\n",
        "\n",
        "# Count of absences\n",
        "attendance_df.filter(col(\"Status\") == \"Absent\").groupBy(\"EmpID\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lvlS95uIZug",
        "outputId": "f06d2a71-9e95-42fe-a8c6-e05d83c041e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "| Department|avg(Salary)|\n",
            "+-----------+-----------+\n",
            "|Engineering|    77500.0|\n",
            "|         HR|    52500.0|\n",
            "|  Marketing|    60000.0|\n",
            "+-----------+-----------+\n",
            "\n",
            "+---------+-----+\n",
            "|ManagerID|count|\n",
            "+---------+-----+\n",
            "|     NULL|    1|\n",
            "|        1|    4|\n",
            "+---------+-----+\n",
            "\n",
            "+-----+-----+\n",
            "|EmpID|count|\n",
            "+-----+-----+\n",
            "|    2|    1|\n",
            "|    4|    2|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attendance percentage\n",
        "from pyspark.sql.functions import count, when\n",
        "\n",
        "attendance_pct_df = attendance_df.groupBy(\"EmpID\") \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"TotalDays\"),\n",
        "        count(when(col(\"Status\") == \"Present\", True)).alias(\"PresentDays\")\n",
        "    ).withColumn(\"AttendancePct\", round(col(\"PresentDays\") / col(\"TotalDays\") * 100, 1))\n",
        "\n",
        "attendance_pct_df.show()\n",
        "\n",
        "# Top 3 by total compensation\n",
        "emp_bonus_df.orderBy(col(\"TotalCompensation\").desc()).show(3)\n",
        "\n",
        "# Multi-level join\n",
        "multi_join_df = employees_df.join(bonuses_df, \"EmpID\").join(attendance_pct_df, \"EmpID\")\n",
        "multi_join_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO9nU4nCM5_v",
        "outputId": "25acb173-21cf-4607-d005-dcbceb0a9078"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+-----------+-------------+\n",
            "|EmpID|TotalDays|PresentDays|AttendancePct|\n",
            "+-----+---------+-----------+-------------+\n",
            "|    2|        2|          1|         50.0|\n",
            "|    4|        2|          0|          0.0|\n",
            "|    5|        2|          2|        100.0|\n",
            "|    1|        2|          2|        100.0|\n",
            "|    3|        2|          2|        100.0|\n",
            "+-----+---------+-----------+-------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------+-----------+-------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalDays|PresentDays|AttendancePct|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------+-----------+-------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|        2|          2|        100.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|        2|          1|         50.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|        2|          2|        100.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|        2|          0|          0.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|        2|          2|        100.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, month, regexp_replace, lpad, substring\n",
        "\n",
        "# Extract year/month from JoinDate\n",
        "employees_df = employees_df.withColumn(\"JoinYear\", year(\"JoinDate\")).withColumn(\"JoinMonth\", month(\"JoinDate\"))\n",
        "\n",
        "# Mask name\n",
        "employees_df = employees_df.withColumn(\"MaskedName\", regexp_replace(\"Name\", \".\", \"*\"))\n",
        "\n",
        "# Employee code\n",
        "employees_df = employees_df.withColumn(\"EmpCode\", lpad(col(\"EmpID\").cast(\"string\"), 3, \"0\"))\n",
        "employees_df = employees_df.withColumn(\"EmpCode\", col(\"EmpCode\").substr(1, 3).alias(\"EmpCode\"))\n",
        "employees_df = employees_df.withColumn(\"EmpCode\", col(\"EmpCode\").cast(\"string\"))\n",
        "employees_df = employees_df.withColumn(\"EmpCode\", col(\"EmpCode\").alias(\"EMP\") + col(\"EmpCode\"))\n",
        "\n",
        "employees_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf9ocjHzM-P1",
        "outputId": "cc2398e5-f895-4f2f-8af2-5f8593f63045"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|    2021|        5|     *****|    2.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|    2020|        3|       ***|    4.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|    2022|        7|    ******|    6.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|    2019|       11|     *****|    8.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|    2023|        1|     *****|   10.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Performance label\n",
        "bonuses_df = bonuses_df.withColumn(\"Performance\",\n",
        "    when(col(\"Bonus\") > 6000, \"High\")\n",
        "    .when(col(\"Bonus\").between(4000, 6000), \"Medium\")\n",
        "    .otherwise(\"Low\")\n",
        ")\n",
        "\n",
        "# Handle nulls\n",
        "employees_df = employees_df.fillna({\"ManagerID\": \"No Manager\"})\n",
        "\n",
        "bonuses_df.show()\n",
        "employees_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njSjxnPUNDJv",
        "outputId": "b587ad19-a925-4400-bc02-aa7828bde0b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----+-----------+\n",
            "|Bonus|EmpID|Year|Performance|\n",
            "+-----+-----+----+-----------+\n",
            "| 5000|    1|2023|     Medium|\n",
            "| 7000|    2|2023|       High|\n",
            "| 6500|    3|2023|       High|\n",
            "| 6000|    4|2023|     Medium|\n",
            "| 4000|    5|2023|     Medium|\n",
            "+-----+-----+----+-----------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|    2021|        5|     *****|    2.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|    2020|        3|       ***|    4.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|    2022|        7|    ******|    6.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|    2019|       11|     *****|    8.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|    2023|        1|     *****|   10.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create database\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS hr\")\n",
        "spark.catalog.setCurrentDatabase(\"hr\")\n",
        "\n",
        "# Register tables\n",
        "employees_df.write.mode(\"overwrite\").saveAsTable(\"employees\")\n",
        "attendance_df.write.mode(\"overwrite\").saveAsTable(\"attendance\")\n",
        "bonuses_df.write.mode(\"overwrite\").saveAsTable(\"bonuses\")\n",
        "\n",
        "# 1. Top paid employee per department\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Department, Name, Salary\n",
        "    FROM employees\n",
        "    WHERE (Department, Salary) IN (\n",
        "        SELECT Department, MAX(Salary) FROM employees GROUP BY Department\n",
        "    )\n",
        "\"\"\").show()\n",
        "\n",
        "# 2. Attendance rate by department\n",
        "spark.sql(\"\"\"\n",
        "    SELECT e.Department,\n",
        "           ROUND(SUM(CASE WHEN a.Status = 'Present' THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 1) AS AttendanceRate\n",
        "    FROM employees e\n",
        "    JOIN attendance a ON e.EmpID = a.EmpID\n",
        "    GROUP BY e.Department\n",
        "\"\"\").show()\n",
        "\n",
        "# 3. Joined after 2021 with salary > 70000\n",
        "spark.sql(\"\"\"\n",
        "    SELECT * FROM employees\n",
        "    WHERE YEAR(JoinDate) > 2021 AND Salary > 70000\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI_nn220NGwc",
        "outputId": "9e5112d0-2f66-4787-d165-aa1050bc97a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+------+\n",
            "| Department| Name|Salary|\n",
            "+-----------+-----+------+\n",
            "|         HR|Anita| 55000|\n",
            "|Engineering|  Raj| 80000|\n",
            "|  Marketing|Aamir| 60000|\n",
            "+-----------+-----+------+\n",
            "\n",
            "+-----------+--------------+\n",
            "| Department|AttendanceRate|\n",
            "+-----------+--------------+\n",
            "|Engineering|          75.0|\n",
            "|         HR|         100.0|\n",
            "|  Marketing|           0.0|\n",
            "+-----------+--------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|    2022|        7|    ******|    6.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf, count, when, round\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Spark session\n",
        "spark = SparkSession.builder.appName(\"HR_Analytics\").getOrCreate()\n",
        "\n",
        "# ✅ 1. Create UDF to classify department\n",
        "def classify_dept(dept):\n",
        "    return \"Tech\" if dept in [\"Engineering\", \"IT\"] else \"Non-Tech\"\n",
        "\n",
        "classify_udf = udf(classify_dept, StringType())\n",
        "\n",
        "# ✅ 2. Add column DeptType to employees\n",
        "employees_df = employees_df.withColumn(\"DeptType\", classify_udf(col(\"Department\")))\n",
        "employees_df.select(\"EmpID\", \"Department\", \"DeptType\").show()\n",
        "\n",
        "#  3. Compute attendance % for each employee\n",
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "attendance_pct_df = attendance_df.groupBy(\"EmpID\") \\\n",
        "    .agg(\n",
        "        (count(when(col(\"Status\") == \"Present\", True)) / count(\"*\") * 100).alias(\"AttendancePct\")\n",
        "    )\n",
        "\n",
        "attendance_pct_df = attendance_pct_df.withColumn(\"AttendancePct\", round(col(\"AttendancePct\"), 2))\n",
        "attendance_pct_df.show()\n",
        "\n",
        "#  4. Join employees with attendance summary\n",
        "emp_attendance_summary = employees_df.join(attendance_pct_df, \"EmpID\", \"left\")\n",
        "emp_attendance_summary.select(\"EmpID\", \"Name\", \"Department\", \"DeptType\", \"AttendancePct\").show()\n",
        "\n",
        "#  5. Create temporary view\n",
        "emp_attendance_summary.createOrReplaceTempView(\"emp_attendance_summary\")\n",
        "\n",
        "#  6. Query the view to verify\n",
        "spark.sql(\"SELECT EmpID, Name, DeptType, AttendancePct FROM emp_attendance_summary ORDER BY EmpID\").show()\n",
        "\n",
        "# 7. Save as Parquet partitioned by Department\n",
        "save_path = base_path + \"emp_attendance_summary/\"  # example: \"/content/drive/MyDrive/HR_Analytics_Data/emp_attendance_summary/\"\n",
        "emp_attendance_summary.write.mode(\"overwrite\").partitionBy(\"Department\").parquet(save_path)\n",
        "\n",
        "# 8. Read back saved Parquet to confirm\n",
        "parquet_df = spark.read.parquet(save_path)\n",
        "parquet_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0wa0zndNNoQ",
        "outputId": "c33270fc-d513-46b8-a34a-11ea06bfd704"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+--------+\n",
            "|EmpID| Department|DeptType|\n",
            "+-----+-----------+--------+\n",
            "|    1|         HR|Non-Tech|\n",
            "|    2|Engineering|    Tech|\n",
            "|    3|Engineering|    Tech|\n",
            "|    4|  Marketing|Non-Tech|\n",
            "|    5|         HR|Non-Tech|\n",
            "+-----+-----------+--------+\n",
            "\n",
            "+-----+-------------+\n",
            "|EmpID|AttendancePct|\n",
            "+-----+-------------+\n",
            "|    2|         50.0|\n",
            "|    4|          0.0|\n",
            "|    5|        100.0|\n",
            "|    1|        100.0|\n",
            "|    3|        100.0|\n",
            "+-----+-------------+\n",
            "\n",
            "+-----+------+-----------+--------+-------------+\n",
            "|EmpID|  Name| Department|DeptType|AttendancePct|\n",
            "+-----+------+-----------+--------+-------------+\n",
            "|    1| Anita|         HR|Non-Tech|        100.0|\n",
            "|    2|   Raj|Engineering|    Tech|         50.0|\n",
            "|    3|Simran|Engineering|    Tech|        100.0|\n",
            "|    4| Aamir|  Marketing|Non-Tech|          0.0|\n",
            "|    5| Nisha|         HR|Non-Tech|        100.0|\n",
            "+-----+------+-----------+--------+-------------+\n",
            "\n",
            "+-----+------+--------+-------------+\n",
            "|EmpID|  Name|DeptType|AttendancePct|\n",
            "+-----+------+--------+-------------+\n",
            "|    1| Anita|Non-Tech|        100.0|\n",
            "|    2|   Raj|    Tech|         50.0|\n",
            "|    3|Simran|    Tech|        100.0|\n",
            "|    4| Aamir|Non-Tech|          0.0|\n",
            "|    5| Nisha|Non-Tech|        100.0|\n",
            "+-----+------+--------+-------------+\n",
            "\n",
            "+-----+------+----------+------+---------+-----------+--------+---------+----------+-------+--------+-------------+-----------+\n",
            "|EmpID|  Name|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|DeptType|AttendancePct| Department|\n",
            "+-----+------+----------+------+---------+-----------+--------+---------+----------+-------+--------+-------------+-----------+\n",
            "|    1| Anita|2021-05-01| 55000|     NULL|        4.1|    2021|        5|     *****|    2.0|Non-Tech|        100.0|         HR|\n",
            "|    5| Nisha|2023-01-05| 50000|        1|        2.4|    2023|        1|     *****|   10.0|Non-Tech|        100.0|         HR|\n",
            "|    2|   Raj|2020-03-15| 80000|        1|        5.2|    2020|        3|       ***|    4.0|    Tech|         50.0|Engineering|\n",
            "|    3|Simran|2022-07-10| 75000|        1|        2.9|    2022|        7|    ******|    6.0|    Tech|        100.0|Engineering|\n",
            "|    4| Aamir|2019-11-20| 60000|        1|        5.6|    2019|       11|     *****|    8.0|Non-Tech|          0.0|  Marketing|\n",
            "+-----+------+----------+------+---------+-----------+--------+---------+----------+-------+--------+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}